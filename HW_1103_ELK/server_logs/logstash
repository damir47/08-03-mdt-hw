2025/09/10 16:55:33 Setting 'xpack.monitoring.enabled' from environment.
Using bundled JDK: /usr/share/logstash/jdk
Sending Logstash logs to /usr/share/logstash/logs which is now configured via log4j2.properties
[2025-09-10T16:56:31,974][INFO ][logstash.runner          ] Log4j configuration path used is: /usr/share/logstash/config/log4j2.properties
[2025-09-10T16:56:32,021][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"9.1.3", "jruby.version"=>"jruby 9.4.13.0 (3.1.4) 2025-06-10 9938a3461f OpenJDK 64-Bit Server VM 21.0.7+6-LTS on 21.0.7+6-LTS +indy +jit [x86_64-linux]"}
[2025-09-10T16:56:32,044][INFO ][logstash.runner          ] JVM bootstrap flags: [-Xms1g, -Xmx1g, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djruby.compile.invokedynamic=true, -XX:+HeapDumpOnOutOfMemoryError, -Djava.security.egd=file:/dev/urandom, -Dlog4j2.isThreadContextMapInheritable=true, -Dls.cgroup.cpuacct.path.override=/, -Dls.cgroup.cpu.path.override=/, -Xmx256m, -Xms256m, -Djruby.regexp.interruptible=true, -Djdk.io.File.enableADS=true, --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED, --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED, --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED, --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED, --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED, --add-opens=java.base/java.security=ALL-UNNAMED, --add-opens=java.base/java.io=ALL-UNNAMED, --add-opens=java.base/java.nio.channels=ALL-UNNAMED, --add-opens=java.base/sun.nio.ch=ALL-UNNAMED, --add-opens=java.management/sun.management=ALL-UNNAMED, -Dio.netty.allocator.maxOrder=11]
[2025-09-10T16:56:32,359][INFO ][org.logstash.jackson.StreamReadConstraintsUtil] Jackson default value override `logstash.jackson.stream-read-constraints.max-string-length` configured to `200000000` (logstash default)
[2025-09-10T16:56:32,360][INFO ][org.logstash.jackson.StreamReadConstraintsUtil] Jackson default value override `logstash.jackson.stream-read-constraints.max-number-length` configured to `10000` (logstash default)
[2025-09-10T16:56:32,360][INFO ][org.logstash.jackson.StreamReadConstraintsUtil] Jackson default value override `logstash.jackson.stream-read-constraints.max-nesting-depth` configured to `1000` (logstash default)
[2025-09-10T16:56:32,403][INFO ][logstash.settings        ] Creating directory {:setting=>"path.queue", :path=>"/usr/share/logstash/data/queue"}
[2025-09-10T16:56:32,422][INFO ][logstash.settings        ] Creating directory {:setting=>"path.dead_letter_queue", :path=>"/usr/share/logstash/data/dead_letter_queue"}
[2025-09-10T16:56:34,120][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>"d6213d1a-94e6-4fdc-8cd4-cce94b2be9dc", :path=>"/usr/share/logstash/data/uuid"}
[2025-09-10T16:56:38,527][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600, :ssl_enabled=>false}
[2025-09-10T16:56:40,341][INFO ][org.reflections.Reflections] Reflections took 266 ms to scan 1 urls, producing 149 keys and 523 values
[2025-09-10T16:56:42,495][INFO ][logstash.javapipeline    ] Pipeline `nginx_pipeline` is configured with `pipeline.ecs_compatibility: v8` setting. All plugins in this pipeline will default to `ecs_compatibility => v8` unless explicitly configured otherwise.
[2025-09-10T16:56:42,572][INFO ][logstash.outputs.elasticsearch][nginx_pipeline] New Elasticsearch output {:class=>"LogStash::Outputs::ElasticSearch", :hosts=>["http://elasticsearch:9200"]}
[2025-09-10T16:56:43,169][INFO ][logstash.outputs.elasticsearch][nginx_pipeline] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elasticsearch:9200/]}}
[2025-09-10T16:56:43,271][INFO ][logstash.outputs.elasticsearch][nginx_pipeline] Failed to perform request {:message=>"Connect to elasticsearch:9200 [elasticsearch/172.18.0.2] failed: Connection refused", :exception=>Manticore::SocketException, :cause=>#<Java::OrgApacheHttpConn::HttpHostConnectException: Connect to elasticsearch:9200 [elasticsearch/172.18.0.2] failed: Connection refused>}
[2025-09-10T16:56:43,275][WARN ][logstash.outputs.elasticsearch][nginx_pipeline] Attempted to resurrect connection to dead ES instance, but got an error {:url=>"http://elasticsearch:9200/", :exception=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :message=>"Elasticsearch Unreachable: [http://elasticsearch:9200/][Manticore::SocketException] Connect to elasticsearch:9200 [elasticsearch/172.18.0.2] failed: Connection refused"}
[2025-09-10T16:56:43,296][INFO ][logstash.outputs.elasticsearch][nginx_pipeline] Not eligible for data streams because config contains one or more settings that are not compatible with data streams: {"index"=>"logs_app_gen-%{+YYYY.MM.dd}"}
[2025-09-10T16:56:43,299][INFO ][logstash.outputs.elasticsearch][nginx_pipeline] Data streams auto configuration (`data_stream => auto` or unset) resolved to `false`
[2025-09-10T16:56:43,305][WARN ][logstash.filters.grok    ][nginx_pipeline] ECS v8 support is a preview of the unreleased ECS v8, and uses the v1 patterns. When Version 8 of the Elastic Common Schema becomes available, this plugin will need to be updated
[2025-09-10T16:56:45,139][WARN ][logstash.javapipeline    ][nginx_pipeline] 'pipeline.ordered' is enabled and is likely less efficient, consider disabling if preserving event order is not necessary
[2025-09-10T16:56:45,199][INFO ][logstash.javapipeline    ][nginx_pipeline] Starting pipeline {:pipeline_id=>"nginx_pipeline", "pipeline.workers"=>1, "pipeline.batch.size"=>1, "pipeline.batch.delay"=>50, "pipeline.max_inflight"=>1, "pipeline.sources"=>["/usr/share/logstash/config/nginx.conf"], :thread=>"#<Thread:0x1ecabb77 /usr/share/logstash/logstash-core/lib/logstash/java_pipeline.rb:138 run>"}
[2025-09-10T16:56:46,802][INFO ][logstash.javapipeline    ][nginx_pipeline] Pipeline Java execution initialization time {"seconds"=>1.6}
[2025-09-10T16:56:46,841][INFO ][logstash.javapipeline    ][nginx_pipeline] Pipeline started {"pipeline.id"=>"nginx_pipeline"}
[2025-09-10T16:56:46,857][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:nginx_pipeline], :non_running_pipelines=>[]}
[2025-09-10T16:56:46,859][INFO ][filewatch.observingtail  ][nginx_pipeline][48c06402f41c6e9a94ca7d37376e7896ad4f33ecc090cd02311ba72deb9f61e2] START, creating Discoverer, Watch with file and sincedb collections
[2025-09-10T16:56:48,480][INFO ][logstash.outputs.elasticsearch][nginx_pipeline] Failed to perform request {:message=>"Connect to elasticsearch:9200 [elasticsearch/172.18.0.2] failed: Connection refused", :exception=>Manticore::SocketException, :cause=>#<Java::OrgApacheHttpConn::HttpHostConnectException: Connect to elasticsearch:9200 [elasticsearch/172.18.0.2] failed: Connection refused>}
[2025-09-10T16:56:48,482][WARN ][logstash.outputs.elasticsearch][nginx_pipeline] Attempted to resurrect connection to dead ES instance, but got an error {:url=>"http://elasticsearch:9200/", :exception=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :message=>"Elasticsearch Unreachable: [http://elasticsearch:9200/][Manticore::SocketException] Connect to elasticsearch:9200 [elasticsearch/172.18.0.2] failed: Connection refused"}
[2025-09-10T16:56:53,493][INFO ][logstash.outputs.elasticsearch][nginx_pipeline] Failed to perform request {:message=>"Connect to elasticsearch:9200 [elasticsearch/172.18.0.2] failed: Connection refused", :exception=>Manticore::SocketException, :cause=>#<Java::OrgApacheHttpConn::HttpHostConnectException: Connect to elasticsearch:9200 [elasticsearch/172.18.0.2] failed: Connection refused>}
[2025-09-10T16:56:53,495][WARN ][logstash.outputs.elasticsearch][nginx_pipeline] Attempted to resurrect connection to dead ES instance, but got an error {:url=>"http://elasticsearch:9200/", :exception=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :message=>"Elasticsearch Unreachable: [http://elasticsearch:9200/][Manticore::SocketException] Connect to elasticsearch:9200 [elasticsearch/172.18.0.2] failed: Connection refused"}
[2025-09-10T16:56:58,509][INFO ][logstash.outputs.elasticsearch][nginx_pipeline] Failed to perform request {:message=>"Connect to elasticsearch:9200 [elasticsearch/172.18.0.2] failed: Connection refused", :exception=>Manticore::SocketException, :cause=>#<Java::OrgApacheHttpConn::HttpHostConnectException: Connect to elasticsearch:9200 [elasticsearch/172.18.0.2] failed: Connection refused>}
[2025-09-10T16:56:58,514][WARN ][logstash.outputs.elasticsearch][nginx_pipeline] Attempted to resurrect connection to dead ES instance, but got an error {:url=>"http://elasticsearch:9200/", :exception=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :message=>"Elasticsearch Unreachable: [http://elasticsearch:9200/][Manticore::SocketException] Connect to elasticsearch:9200 [elasticsearch/172.18.0.2] failed: Connection refused"}
[2025-09-10T16:57:04,227][WARN ][logstash.outputs.elasticsearch][nginx_pipeline] Restored connection to ES instance {:url=>"http://elasticsearch:9200/"}
[2025-09-10T16:57:04,886][INFO ][logstash.outputs.elasticsearch][nginx_pipeline] Elasticsearch version determined (9.1.3) {:es_version=>9}
[2025-09-10T16:57:04,911][ERROR][logstash.outputs.elasticsearch][nginx_pipeline] Unable to get license information {:url=>"http://elasticsearch:9200/", :exception=>LogStash::Outputs::ElasticSearch::HttpClient::Pool::BadResponseCodeError, :message=>"Got response code '404' contacting Elasticsearch at URL 'http://elasticsearch:9200/_license'"}
[2025-09-10T16:57:04,913][ERROR][logstash.outputs.elasticsearch][nginx_pipeline] Could not connect to a compatible version of Elasticsearch {:url=>"http://elasticsearch:9200/"}
[2025-09-10T16:57:08,948][WARN ][logstash.outputs.elasticsearch][nginx_pipeline] Restored connection to ES instance {:url=>"http://elasticsearch:9200/"}
[2025-09-10T16:57:13,442][INFO ][logstash.outputs.elasticsearch][nginx_pipeline] Using a default mapping template {:es_version=>9, :ecs_compatibility=>:v8}
[2025-09-10T16:57:14,053][INFO ][logstash.outputs.elasticsearch][nginx_pipeline] Installing Elasticsearch template {:name=>"ecs-logstash"}
